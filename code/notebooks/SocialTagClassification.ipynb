{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8061643",
   "metadata": {},
   "source": [
    "# Social Media Hashtag Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f1eae",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FF00FF\">Import Libraries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "982f57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import html\n",
    "import string\n",
    "import unicodedata\n",
    "  \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "18668412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  leadersocialhashtags       SpecialTags\n",
      "0    ['#academy', '#training', '#education', '#foot...              None\n",
      "1    ['#initiative', '#love', '#together', '#motiva...              None\n",
      "2    ['#echo', '#the', '#season', '#overwatch', '#a...              None\n",
      "3    ['#mosaic', '#art', '#mosaicart', '#mosaico', ...              None\n",
      "4    ['#lgbtq', '#lgbt', '#gay', '#pride', '#loveis...             LGBTQ\n",
      "..                                                 ...               ...\n",
      "124  ['#winner', '#win', '#love', '#giveaway', '#bl...              None\n",
      "125  ['#lgbtq', '#lgbt', '#gay', '#pride', '#loveis...             LGBTQ\n",
      "126  ['#differentlyabled', '#disabilityawareness', ...  DifferentlyAbled\n",
      "127  ['#sport', '#fitness', '#training', '#gym', '#...              None\n",
      "128  ['#echo', '#the', '#season', '#overwatch', '#a...              None\n",
      "\n",
      "[129 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"SocialHashTagdata.xlsx\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c58edfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129 entries, 0 to 128\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   leadersocialhashtags  129 non-null    object\n",
      " 1   SpecialTags           129 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e4f20",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FF00FF\">Data Preprocessing</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "744e2ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class te get text. \n",
    "class preprocessing:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    #Cleaning and stripping HTML\n",
    "    def remove_html_tags(self,text):\n",
    "        clean = re.compile('<.*?>')\n",
    "        cleantext = re.sub(clean, '', text)\n",
    "        return cleantext\n",
    "\n",
    "    #Removing Escaping characters &lt\n",
    "    def escaping_html_char(self,doc):\n",
    "        cleandoc = html.unescape(doc)\n",
    "        return cleandoc\n",
    "    \n",
    "    #Removing newline & extra spaces\n",
    "    def textcleaning(self,doc):\n",
    "        # remove extra newlines\n",
    "        a = doc.replace(\"\\\\n\",\".\").strip()\n",
    "        a = a.replace(\"\\\\r\",\".\").strip()\n",
    "        #a = re.sub(r'\\d+','',a)# remove numbers\n",
    "        cleandoc = re.sub(\"\\s+\",\" \", a)\n",
    "        return cleandoc\n",
    "    \n",
    "    def text_norm(self,doc):\n",
    "        cleandoc = doc.lower()\n",
    "        return cleandoc\n",
    "    \n",
    "    \n",
    "    abbr_dict={\n",
    "        \"what's\":\"what is\",\n",
    "        \"what're\":\"what are\",\n",
    "        \"who's\":\"who is\",\n",
    "        \"who're\":\"who are\",\n",
    "        \"where's\":\"where is\",\n",
    "        \"where're\":\"where are\",\n",
    "        \"when's\":\"when is\",\n",
    "        \"when're\":\"when are\",\n",
    "        \"how's\":\"how is\",\n",
    "        \"how're\":\"how are\",\n",
    "\n",
    "        \"i'm\":\"i am\",\n",
    "        \"we're\":\"we are\",\n",
    "        \"you're\":\"you are\",\n",
    "        \"they're\":\"they are\",\n",
    "        \"it's\":\"it is\",\n",
    "        \"he's\":\"he is\",\n",
    "        \"she's\":\"she is\",\n",
    "        \"that's\":\"that is\",\n",
    "        \"there's\":\"there is\",\n",
    "        \"there're\":\"there are\",\n",
    "\n",
    "        \"i've\":\"i have\",\n",
    "        \"we've\":\"we have\",\n",
    "        \"you've\":\"you have\",\n",
    "        \"they've\":\"they have\",\n",
    "        \"who've\":\"who have\",\n",
    "        \"would've\":\"would have\",\n",
    "        \"not've\":\"not have\",\n",
    "\n",
    "        \"i'll\":\"i will\",\n",
    "        \"we'll\":\"we will\",\n",
    "        \"you'll\":\"you will\",\n",
    "        \"he'll\":\"he will\",\n",
    "        \"she'll\":\"she will\",\n",
    "        \"it'll\":\"it will\",\n",
    "        \"they'll\":\"they will\",\n",
    "\n",
    "        \"isn't\":\"is not\",\n",
    "        \"wasn't\":\"was not\",\n",
    "        \"aren't\":\"are not\",\n",
    "        \"weren't\":\"were not\",\n",
    "        \"can't\":\"can not\",\n",
    "        \"couldn't\":\"could not\",\n",
    "        \"don't\":\"do not\",\n",
    "        \"didn't\":\"did not\",\n",
    "        \"shouldn't\":\"should not\",\n",
    "        \"wouldn't\":\"would not\",\n",
    "        \"doesn't\":\"does not\",\n",
    "        \"haven't\":\"have not\",\n",
    "        \"hasn't\":\"has not\",\n",
    "        \"hadn't\":\"had not\",\n",
    "        \"won't\":\"will not\"\n",
    "    }\n",
    "\n",
    "    def process_data(self,doc):\n",
    "        for key, value in self.abbr_dict.items():\n",
    "            doc = doc.replace(key,value)\n",
    "        return doc\n",
    "\n",
    "    # Removing accented characters\n",
    "    # A simple example — converting é to e.\n",
    "    def decode_text(self,doc):\n",
    "        cleandoc = unicodedata.normalize('NFKD', doc).encode('ascii','ignore').decode(\"utf8\")\n",
    "        return cleandoc\n",
    "    \n",
    "    def text_tokenize(self,doc):\n",
    "        return word_tokenize(doc)\n",
    "    \n",
    "    def remove_stopwords(self,words):\n",
    "        # set of stop words\n",
    "        stop_words = set(stopwords.words('english')) \n",
    "        stext = [] \n",
    "        for w in words:\n",
    "            if w not in stop_words:\n",
    "                stext.append(w)\n",
    "        return stext\n",
    "    \n",
    "    def remove_punctuation(self,doc):\n",
    "        #chars = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~'\n",
    "        #table = str.maketrans(chars, ' '*len(chars))\n",
    "        table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "        ##str.maketrans('', '', string.punctuation)\n",
    "        cleandoc = doc.translate(table)\n",
    "        return cleandoc\n",
    "    \n",
    "    def data_preprocessing(self,doc,w_stop=True):\n",
    "\n",
    "        doc = str(doc)\n",
    "\n",
    "        step1 = self.remove_html_tags(doc)            # Cleaning and stripping HTML\n",
    "        step2 = self.escaping_html_char(step1)        # Removing Escaping characters &lt\n",
    "        step3 = self.textcleaning(step2)              # Removing newline & extra spaces\n",
    "        step4 = self.text_norm(step3)                 # Case Normalization\n",
    "        step5 = self.process_data(step4)              # Transforming abbreviations\n",
    "        step6 = self.remove_punctuation(step5)        # Remove punctuation\n",
    "        step7 = self.decode_text(step6)               # Text encoding - Removing accented characters\n",
    "        step8 = self.text_tokenize(step7)             # Tokenization\n",
    "\n",
    "        if w_stop:\n",
    "            step11 = self.remove_stopwords(step8)\n",
    "            cleandoc = \" \".join(step11)\n",
    "        else:\n",
    "            cleandoc = \" \".join(step8)\n",
    "\n",
    "        return cleandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "76b4b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = preprocessing()\n",
    "df['clean_hashtags'] = df['leadersocialhashtags'].apply(pre.data_preprocessing,w_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b7323dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_hashtags</th>\n",
       "      <th>leadersocialhashtags</th>\n",
       "      <th>SpecialTags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy training education football school fit...</td>\n",
       "      <td>['#academy', '#training', '#education', '#foot...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>initiative love together motivation covid insp...</td>\n",
       "      <td>['#initiative', '#love', '#together', '#motiva...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>echo season overwatch alexa stihl lawncare lov...</td>\n",
       "      <td>['#echo', '#the', '#season', '#overwatch', '#a...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mosaic art mosaicart mosaico interiordesign de...</td>\n",
       "      <td>['#mosaic', '#art', '#mosaicart', '#mosaico', ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgbtq lgbt gay pride loveislove queer lesbian ...</td>\n",
       "      <td>['#lgbtq', '#lgbt', '#gay', '#pride', '#loveis...</td>\n",
       "      <td>LGBTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>winner win love giveaway blackpink motivation ...</td>\n",
       "      <td>['#winner', '#win', '#love', '#giveaway', '#bl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>lgbtq lgbt gay pride loveislove queer lesbian ...</td>\n",
       "      <td>['#lgbtq', '#lgbt', '#gay', '#pride', '#loveis...</td>\n",
       "      <td>LGBTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>differentlyabled disabilityawareness disabilit...</td>\n",
       "      <td>['#differentlyabled', '#disabilityawareness', ...</td>\n",
       "      <td>DifferentlyAbled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>sport fitness training gym motivation workout ...</td>\n",
       "      <td>['#sport', '#fitness', '#training', '#gym', '#...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>echo season overwatch alexa stihl lawncare lov...</td>\n",
       "      <td>['#echo', '#the', '#season', '#overwatch', '#a...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        clean_hashtags  \\\n",
       "0    academy training education football school fit...   \n",
       "1    initiative love together motivation covid insp...   \n",
       "2    echo season overwatch alexa stihl lawncare lov...   \n",
       "3    mosaic art mosaicart mosaico interiordesign de...   \n",
       "4    lgbtq lgbt gay pride loveislove queer lesbian ...   \n",
       "..                                                 ...   \n",
       "124  winner win love giveaway blackpink motivation ...   \n",
       "125  lgbtq lgbt gay pride loveislove queer lesbian ...   \n",
       "126  differentlyabled disabilityawareness disabilit...   \n",
       "127  sport fitness training gym motivation workout ...   \n",
       "128  echo season overwatch alexa stihl lawncare lov...   \n",
       "\n",
       "                                  leadersocialhashtags       SpecialTags  \n",
       "0    ['#academy', '#training', '#education', '#foot...              None  \n",
       "1    ['#initiative', '#love', '#together', '#motiva...              None  \n",
       "2    ['#echo', '#the', '#season', '#overwatch', '#a...              None  \n",
       "3    ['#mosaic', '#art', '#mosaicart', '#mosaico', ...              None  \n",
       "4    ['#lgbtq', '#lgbt', '#gay', '#pride', '#loveis...             LGBTQ  \n",
       "..                                                 ...               ...  \n",
       "124  ['#winner', '#win', '#love', '#giveaway', '#bl...              None  \n",
       "125  ['#lgbtq', '#lgbt', '#gay', '#pride', '#loveis...             LGBTQ  \n",
       "126  ['#differentlyabled', '#disabilityawareness', ...  DifferentlyAbled  \n",
       "127  ['#sport', '#fitness', '#training', '#gym', '#...              None  \n",
       "128  ['#echo', '#the', '#season', '#overwatch', '#a...              None  \n",
       "\n",
       "[129 rows x 3 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['clean_hashtags','leadersocialhashtags','SpecialTags']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c2c95f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FF00FF\">Training spaCy model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7186485a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Add the TextCategorizer to the empty model\n",
    "text = nlp.add_pipe(\"textcat\")\n",
    "\n",
    "# Adding labels to the `ner`\n",
    "text.add_label('LGBTQ')\n",
    "text.add_label('DifferentlyAbled')\n",
    "text.add_label('None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "527f98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = df['clean_hashtags'].values\n",
    "train_labels = [{'cats': {'LGBTQ': SpecialTags == 'LGBTQ',\n",
    "                          'DifferentlyAbled': SpecialTags == 'DifferentlyAbled',\n",
    "                          'None' : SpecialTags == 'None'}} \n",
    "                for SpecialTags in df['SpecialTags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0e3264c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('academy training education football school fitness beauty makeup academia phoenix art love dance sports joaquin soccer learning online motivation sport instagram instagood coaching music students oscar fashion fun',\n",
       "  {'cats': {'LGBTQ': False, 'DifferentlyAbled': False, 'None': True}}),\n",
       " ('initiative love together motivation covid inspiration change india education success changemakers peace social unicef slapcollective youths spread unesco changebelievers indianyouths support changeseekers harmony youngindia globalchangemakers slapwale lifeskills unyouths socialventure rurban',\n",
       "  {'cats': {'LGBTQ': False, 'DifferentlyAbled': False, 'None': True}}),\n",
       " ('echo season overwatch alexa stihl lawncare love amazon echodot mercy landscapers instagram widowmaker dva art mccree clarkegriffin genji octaviablake amazonecho reaper echocardiography lucio music bellamyblake zenyatta tech tracer blizzard',\n",
       "  {'cats': {'LGBTQ': False, 'DifferentlyAbled': False, 'None': True}})]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = list(zip(train_texts, train_labels))\n",
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a8ac7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spacy(data,iterations):\n",
    "    train_data=data\n",
    "    random.seed(1)\n",
    "    spacy.util.fix_random_seed(1)\n",
    "    optimizer = nlp.begin_training()\n",
    "\n",
    "    losses = {}\n",
    "    for epoch in range(iterations):\n",
    "        random.shuffle(train_data)\n",
    "        # Create the batch generator with batch size = 8\n",
    "        batches = minibatch(train_data, size=8)\n",
    "        # Iterate through minibatches\n",
    "        for batch in batches:\n",
    "            for text, labels in batch:\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, labels)\n",
    "                nlp.update([example], sgd=optimizer, losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8ec4e2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'textcat': 12.958285689553069}\n",
      "{'textcat': 14.97433874851104}\n",
      "{'textcat': 16.972505053846113}\n",
      "{'textcat': 19.349783979412464}\n",
      "{'textcat': 21.374505578138407}\n",
      "{'textcat': 26.069019476842033}\n",
      "{'textcat': 28.07512961535921}\n",
      "{'textcat': 30.110771911050456}\n",
      "{'textcat': 32.17944538065903}\n",
      "{'textcat': 35.00512049565695}\n",
      "{'textcat': 37.02922410251419}\n",
      "{'textcat': 39.04329633680619}\n",
      "{'textcat': 41.051109849925574}\n",
      "{'textcat': 43.59608092927129}\n",
      "{'textcat': 45.636809481919556}\n",
      "{'textcat': 47.644617303532264}\n",
      "{'textcat': 49.65290326647114}\n",
      "{'textcat': 51.665213018849116}\n",
      "{'textcat': 53.66556861308786}\n",
      "{'textcat': 55.67372149601794}\n"
     ]
    }
   ],
   "source": [
    "hashtaganalytics = train_spacy(train_data, iterations = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e80cd",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FF00FF\">Predicting Hashtags based on spaCy model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5e46e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA = df[['clean_hashtags']].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "def test_spacy(data):\n",
    "    test_texts = data['clean_hashtags'].values\n",
    "        #hashtaganalytics = SPACY_obj.get(\"spacy_model\")\n",
    "    texts = test_texts\n",
    "    docs = [nlp.tokenizer(text) for text in texts]\n",
    "\n",
    "    # Use textcat to get the scores for each doc\n",
    "    textcat = nlp.get_pipe('textcat')\n",
    "    scores = textcat.predict(docs)\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "997d3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the scores, find the label with the highest score/probability\n",
    "def test_spacy_execute():\n",
    "    predicted_labels = test_spacy(TEST_DATA).argmax(axis=1)\n",
    "    predicted_tags = [textcat.labels[label] for label in predicted_labels]\n",
    "\n",
    "    labels = np.array(predicted_tags)\n",
    "    predictedlabel = pd.DataFrame({'Label': labels}, columns=['Label'])\n",
    "\n",
    "    result = pd.concat([TEST_DATA, predictedlabel], axis=1, join='inner')\n",
    "    return (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "0218a120",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_social = pd.read_csv(\"file_name.csv\", sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f430a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_social_test = df_social[['dunsNum','leadersocialhashtags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0e5ad632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arvin\\AppData\\Local\\Temp\\ipykernel_1196\\2781744218.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_social_test['clean_hashtags'] = df_social_test['leadersocialhashtags'].apply(pre.data_preprocessing,w_stop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dunsNum</th>\n",
       "      <th>leadersocialhashtags</th>\n",
       "      <th>clean_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58168600</td>\n",
       "      <td>['#academy', '#training', '#education', '#foot...</td>\n",
       "      <td>academy training education football school fit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>605485861</td>\n",
       "      <td>['#initiative', '#love', '#together', '#motiva...</td>\n",
       "      <td>initiative love together motivation covid insp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>783598485</td>\n",
       "      <td>['#echo', '#the', '#season', '#overwatch', '#a...</td>\n",
       "      <td>echo season overwatch alexa stihl lawncare lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20825064</td>\n",
       "      <td>['#mosaic', '#art', '#mosaicart', '#mosaico', ...</td>\n",
       "      <td>mosaic art mosaicart mosaico interiordesign de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148015845</td>\n",
       "      <td>['#lgbtq', '#lgbt', '#gay', '#pride', '#loveis...</td>\n",
       "      <td>lgbtq lgbt gay pride loveislove queer lesbian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>79688478</td>\n",
       "      <td>['#teacher', '#teachersofinstagram', '#educati...</td>\n",
       "      <td>teacher teachersofinstagram education school t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>619658904</td>\n",
       "      <td>['#academy', '#training', '#education', '#foot...</td>\n",
       "      <td>academy training education football school fit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>787916092</td>\n",
       "      <td>['#differentlyabled', '#disabilityawareness', ...</td>\n",
       "      <td>differentlyabled disabilityawareness disabilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>73886782</td>\n",
       "      <td>['#differentlyabled', '#disabilityawareness', ...</td>\n",
       "      <td>differentlyabled disabilityawareness disabilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>70765601</td>\n",
       "      <td>['#sport', '#fitness', '#training', '#gym', '#...</td>\n",
       "      <td>sport fitness training gym motivation workout ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dunsNum                               leadersocialhashtags  \\\n",
       "0     58168600  ['#academy', '#training', '#education', '#foot...   \n",
       "1    605485861  ['#initiative', '#love', '#together', '#motiva...   \n",
       "2    783598485  ['#echo', '#the', '#season', '#overwatch', '#a...   \n",
       "3     20825064  ['#mosaic', '#art', '#mosaicart', '#mosaico', ...   \n",
       "4    148015845  ['#lgbtq', '#lgbt', '#gay', '#pride', '#loveis...   \n",
       "..         ...                                                ...   \n",
       "242   79688478  ['#teacher', '#teachersofinstagram', '#educati...   \n",
       "243  619658904  ['#academy', '#training', '#education', '#foot...   \n",
       "244  787916092  ['#differentlyabled', '#disabilityawareness', ...   \n",
       "245   73886782  ['#differentlyabled', '#disabilityawareness', ...   \n",
       "246   70765601  ['#sport', '#fitness', '#training', '#gym', '#...   \n",
       "\n",
       "                                        clean_hashtags  \n",
       "0    academy training education football school fit...  \n",
       "1    initiative love together motivation covid insp...  \n",
       "2    echo season overwatch alexa stihl lawncare lov...  \n",
       "3    mosaic art mosaicart mosaico interiordesign de...  \n",
       "4    lgbtq lgbt gay pride loveislove queer lesbian ...  \n",
       "..                                                 ...  \n",
       "242  teacher teachersofinstagram education school t...  \n",
       "243  academy training education football school fit...  \n",
       "244  differentlyabled disabilityawareness disabilit...  \n",
       "245  differentlyabled disabilityawareness disabilit...  \n",
       "246  sport fitness training gym motivation workout ...  \n",
       "\n",
       "[247 rows x 3 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = preprocessing()\n",
    "df_social_test['clean_hashtags'] = df_social_test['leadersocialhashtags'].apply(pre.data_preprocessing,w_stop=True)\n",
    "df_social_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5ac32c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA=df_social_test[['clean_hashtags']]\n",
    "TEST_RESULT = test_spacy_execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0a8a1c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dunsNum</th>\n",
       "      <th>leadersocialhashtags</th>\n",
       "      <th>clean_hashtags</th>\n",
       "      <th>clean_hashtags</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58168600</td>\n",
       "      <td>['#academy', '#training', '#education', '#foot...</td>\n",
       "      <td>academy training education football school fit...</td>\n",
       "      <td>academy training education football school fit...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>605485861</td>\n",
       "      <td>['#initiative', '#love', '#together', '#motiva...</td>\n",
       "      <td>initiative love together motivation covid insp...</td>\n",
       "      <td>initiative love together motivation covid insp...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>783598485</td>\n",
       "      <td>['#echo', '#the', '#season', '#overwatch', '#a...</td>\n",
       "      <td>echo season overwatch alexa stihl lawncare lov...</td>\n",
       "      <td>echo season overwatch alexa stihl lawncare lov...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20825064</td>\n",
       "      <td>['#mosaic', '#art', '#mosaicart', '#mosaico', ...</td>\n",
       "      <td>mosaic art mosaicart mosaico interiordesign de...</td>\n",
       "      <td>mosaic art mosaicart mosaico interiordesign de...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148015845</td>\n",
       "      <td>['#lgbtq', '#lgbt', '#gay', '#pride', '#loveis...</td>\n",
       "      <td>lgbtq lgbt gay pride loveislove queer lesbian ...</td>\n",
       "      <td>lgbtq lgbt gay pride loveislove queer lesbian ...</td>\n",
       "      <td>LGBTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>79688478</td>\n",
       "      <td>['#teacher', '#teachersofinstagram', '#educati...</td>\n",
       "      <td>teacher teachersofinstagram education school t...</td>\n",
       "      <td>teacher teachersofinstagram education school t...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>619658904</td>\n",
       "      <td>['#academy', '#training', '#education', '#foot...</td>\n",
       "      <td>academy training education football school fit...</td>\n",
       "      <td>academy training education football school fit...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>787916092</td>\n",
       "      <td>['#differentlyabled', '#disabilityawareness', ...</td>\n",
       "      <td>differentlyabled disabilityawareness disabilit...</td>\n",
       "      <td>differentlyabled disabilityawareness disabilit...</td>\n",
       "      <td>DifferentlyAbled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>73886782</td>\n",
       "      <td>['#differentlyabled', '#disabilityawareness', ...</td>\n",
       "      <td>differentlyabled disabilityawareness disabilit...</td>\n",
       "      <td>differentlyabled disabilityawareness disabilit...</td>\n",
       "      <td>DifferentlyAbled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>70765601</td>\n",
       "      <td>['#sport', '#fitness', '#training', '#gym', '#...</td>\n",
       "      <td>sport fitness training gym motivation workout ...</td>\n",
       "      <td>sport fitness training gym motivation workout ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dunsNum                               leadersocialhashtags  \\\n",
       "0     58168600  ['#academy', '#training', '#education', '#foot...   \n",
       "1    605485861  ['#initiative', '#love', '#together', '#motiva...   \n",
       "2    783598485  ['#echo', '#the', '#season', '#overwatch', '#a...   \n",
       "3     20825064  ['#mosaic', '#art', '#mosaicart', '#mosaico', ...   \n",
       "4    148015845  ['#lgbtq', '#lgbt', '#gay', '#pride', '#loveis...   \n",
       "..         ...                                                ...   \n",
       "242   79688478  ['#teacher', '#teachersofinstagram', '#educati...   \n",
       "243  619658904  ['#academy', '#training', '#education', '#foot...   \n",
       "244  787916092  ['#differentlyabled', '#disabilityawareness', ...   \n",
       "245   73886782  ['#differentlyabled', '#disabilityawareness', ...   \n",
       "246   70765601  ['#sport', '#fitness', '#training', '#gym', '#...   \n",
       "\n",
       "                                        clean_hashtags  \\\n",
       "0    academy training education football school fit...   \n",
       "1    initiative love together motivation covid insp...   \n",
       "2    echo season overwatch alexa stihl lawncare lov...   \n",
       "3    mosaic art mosaicart mosaico interiordesign de...   \n",
       "4    lgbtq lgbt gay pride loveislove queer lesbian ...   \n",
       "..                                                 ...   \n",
       "242  teacher teachersofinstagram education school t...   \n",
       "243  academy training education football school fit...   \n",
       "244  differentlyabled disabilityawareness disabilit...   \n",
       "245  differentlyabled disabilityawareness disabilit...   \n",
       "246  sport fitness training gym motivation workout ...   \n",
       "\n",
       "                                        clean_hashtags             Label  \n",
       "0    academy training education football school fit...              None  \n",
       "1    initiative love together motivation covid insp...              None  \n",
       "2    echo season overwatch alexa stihl lawncare lov...              None  \n",
       "3    mosaic art mosaicart mosaico interiordesign de...              None  \n",
       "4    lgbtq lgbt gay pride loveislove queer lesbian ...             LGBTQ  \n",
       "..                                                 ...               ...  \n",
       "242  teacher teachersofinstagram education school t...              None  \n",
       "243  academy training education football school fit...              None  \n",
       "244  differentlyabled disabilityawareness disabilit...  DifferentlyAbled  \n",
       "245  differentlyabled disabilityawareness disabilit...  DifferentlyAbled  \n",
       "246  sport fitness training gym motivation workout ...              None  \n",
       "\n",
       "[247 rows x 5 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([df_social_test, TEST_RESULT], axis=1, join='inner')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ea87551c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dunsNum</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58168600</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>605485861</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>783598485</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20825064</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148015845</td>\n",
       "      <td>LGBTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>79688478</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>619658904</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>787916092</td>\n",
       "      <td>DifferentlyAbled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>73886782</td>\n",
       "      <td>DifferentlyAbled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>70765601</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dunsNum             Label\n",
       "0     58168600              None\n",
       "1    605485861              None\n",
       "2    783598485              None\n",
       "3     20825064              None\n",
       "4    148015845             LGBTQ\n",
       "..         ...               ...\n",
       "242   79688478              None\n",
       "243  619658904              None\n",
       "244  787916092  DifferentlyAbled\n",
       "245   73886782  DifferentlyAbled\n",
       "246   70765601              None\n",
       "\n",
       "[247 rows x 2 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[['Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "decf57d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dunsNum</th>\n",
       "      <th>leadergender</th>\n",
       "      <th>leader_race_expanded</th>\n",
       "      <th>isWomanOwned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58168600</td>\n",
       "      <td>female</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>605485861</td>\n",
       "      <td>male</td>\n",
       "      <td>White or European American</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>783598485</td>\n",
       "      <td>female</td>\n",
       "      <td>White or European American</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20825064</td>\n",
       "      <td>male</td>\n",
       "      <td>White or European American</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148015845</td>\n",
       "      <td>male</td>\n",
       "      <td>White or European American</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>79688478</td>\n",
       "      <td>male</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>619658904</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>787916092</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>73886782</td>\n",
       "      <td>male</td>\n",
       "      <td>White or European American</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>70765601</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dunsNum leadergender        leader_race_expanded isWomanOwned\n",
       "0     58168600       female   Black or African-American          YES\n",
       "1    605485861         male  White or European American           NO\n",
       "2    783598485       female  White or European American          YES\n",
       "3     20825064         male  White or European American           NO\n",
       "4    148015845         male  White or European American           NO\n",
       "..         ...          ...                         ...          ...\n",
       "242   79688478         male   Black or African-American           NO\n",
       "243  619658904       female                       Asian          YES\n",
       "244  787916092       female                       Asian          YES\n",
       "245   73886782         male  White or European American           NO\n",
       "246   70765601         male                       Asian           NO\n",
       "\n",
       "[247 rows x 4 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b3cef5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dunsNum</th>\n",
       "      <th>leadergender</th>\n",
       "      <th>leader_race_expanded</th>\n",
       "      <th>isWomanOwned</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58168600</td>\n",
       "      <td>female</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>605485861</td>\n",
       "      <td>male</td>\n",
       "      <td>White or European American</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>783598485</td>\n",
       "      <td>female</td>\n",
       "      <td>White or European American</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20825064</td>\n",
       "      <td>male</td>\n",
       "      <td>White or European American</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148015845</td>\n",
       "      <td>male</td>\n",
       "      <td>White or European American</td>\n",
       "      <td>NO</td>\n",
       "      <td>LGBTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>79688478</td>\n",
       "      <td>male</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>619658904</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>787916092</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>YES</td>\n",
       "      <td>DifferentlyAbled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>73886782</td>\n",
       "      <td>male</td>\n",
       "      <td>White or European American</td>\n",
       "      <td>NO</td>\n",
       "      <td>DifferentlyAbled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>70765601</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>NO</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dunsNum leadergender        leader_race_expanded isWomanOwned  \\\n",
       "0     58168600       female   Black or African-American          YES   \n",
       "1    605485861         male  White or European American           NO   \n",
       "2    783598485       female  White or European American          YES   \n",
       "3     20825064         male  White or European American           NO   \n",
       "4    148015845         male  White or European American           NO   \n",
       "..         ...          ...                         ...          ...   \n",
       "242   79688478         male   Black or African-American           NO   \n",
       "243  619658904       female                       Asian          YES   \n",
       "244  787916092       female                       Asian          YES   \n",
       "245   73886782         male  White or European American           NO   \n",
       "246   70765601         male                       Asian           NO   \n",
       "\n",
       "                Label  \n",
       "0                None  \n",
       "1                None  \n",
       "2                None  \n",
       "3                None  \n",
       "4               LGBTQ  \n",
       "..                ...  \n",
       "242              None  \n",
       "243              None  \n",
       "244  DifferentlyAbled  \n",
       "245  DifferentlyAbled  \n",
       "246              None  \n",
       "\n",
       "[247 rows x 5 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldataset = pd.concat([df_social[['dunsNum','leadergender','leader_race_expanded','isWomanOwned']], result[['Label']]], axis=1, join='inner')\n",
    "finaldataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c6d282ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldataset.to_csv('final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa04f700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
